{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8686a20-a8e4-4660-9792-b942acb6083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "MODELS_DIR = os.path.join(DATA_DIR, 'models')\n",
    "for dir in [DATA_DIR, MODELS_DIR]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b9866-e071-4369-8d09-a9a6c2682714",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4a93b3-58c4-4ecc-aa28-28368781227c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (C:\\Users\\trigu\\venv\\lib\\site-packages\\object_detection\\protos\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m    \u001b[38;5;66;03m# Suppress TensorFlow logging\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_map_util\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_util\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization_utils \u001b[38;5;28;01mas\u001b[39;00m viz_utils\n",
      "File \u001b[1;32m~\\venv\\lib\\site-packages\\object_detection\\utils\\label_map_util.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_int_label_map_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_label_map\u001b[39m(label_map):\n\u001b[0;32m     25\u001b[0m   \u001b[38;5;124;03m\"\"\"Checks if a label map is valid.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    ValueError: if label map is invalid.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (C:\\Users\\trigu\\venv\\lib\\site-packages\\object_detection\\protos\\__init__.py)"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8f01f2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.0.0\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "asttokens==2.0.5\n",
      "astunparse==1.6.3\n",
      "attrs==21.4.0\n",
      "backcall==0.2.0\n",
      "beautifulsoup4==4.11.1\n",
      "bleach==5.0.0\n",
      "cachetools==5.1.0\n",
      "certifi==2022.5.18.1\n",
      "cffi==1.15.0\n",
      "charset-normalizer==2.0.12\n",
      "cloudpickle==2.1.0\n",
      "colorama==0.4.4\n",
      "contextlib2==21.6.0\n",
      "cycler==0.11.0\n",
      "Cython==0.29.30\n",
      "debugpy==1.6.0\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "dm-tree==0.1.7\n",
      "entrypoints==0.4\n",
      "env==0.1.0\n",
      "executing==0.8.3\n",
      "fastjsonschema==2.15.3\n",
      "flatbuffers==1.12\n",
      "fonttools==4.33.3\n",
      "gast==0.4.0\n",
      "gin-config==0.5.0\n",
      "google-auth==2.6.6\n",
      "google-auth-oauthlib==0.4.6\n",
      "google-pasta==0.2.0\n",
      "grpcio==1.46.3\n",
      "gym==0.21.0\n",
      "gym-notices==0.0.6\n",
      "h5py==3.7.0\n",
      "idna==3.3\n",
      "importlib-metadata==4.11.4\n",
      "ipykernel==6.13.0\n",
      "ipython==8.4.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.7.0\n",
      "jedi==0.18.1\n",
      "Jinja2==3.1.2\n",
      "jsonschema==4.5.1\n",
      "jupyter==1.0.0\n",
      "jupyter-client==7.3.1\n",
      "jupyter-console==6.4.3\n",
      "jupyter-core==4.10.0\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab-widgets==1.1.0\n",
      "keras==2.9.0\n",
      "Keras-Preprocessing==1.1.2\n",
      "kiwisolver==1.4.2\n",
      "libclang==14.0.1\n",
      "lxml==4.9.0\n",
      "Markdown==3.3.7\n",
      "MarkupSafe==2.1.1\n",
      "matplotlib==3.5.2\n",
      "matplotlib-inline==0.1.3\n",
      "mistune==0.8.4\n",
      "nbclient==0.6.3\n",
      "nbconvert==6.5.0\n",
      "nbformat==5.4.0\n",
      "nest-asyncio==1.5.5\n",
      "notebook==6.4.11\n",
      "numpy==1.22.4\n",
      "oauthlib==3.2.0\n",
      "object-detection==0.0.3\n",
      "opencv-python==4.6.0.66\n",
      "opt-einsum==3.3.0\n",
      "packaging==21.3\n",
      "pandas==1.4.2\n",
      "pandocfilters==1.5.0\n",
      "parso==0.8.3\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.1.1\n",
      "prometheus-client==0.14.1\n",
      "prompt-toolkit==3.0.29\n",
      "protobuf==3.19.4\n",
      "psutil==5.9.1\n",
      "pure-eval==0.2.2\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser==2.21\n",
      "pygame==2.1.0\n",
      "Pygments==2.12.0\n",
      "pyparsing==3.0.9\n",
      "pyrsistent==0.18.1\n",
      "python-dateutil==2.8.2\n",
      "pytz==2022.1\n",
      "pywin32==304\n",
      "pywinpty==2.0.5\n",
      "pyzmq==23.0.0\n",
      "qtconsole==5.3.0\n",
      "QtPy==2.1.0\n",
      "requests==2.27.1\n",
      "requests-oauthlib==1.3.1\n",
      "rsa==4.8\n",
      "Send2Trash==1.8.0\n",
      "six==1.16.0\n",
      "soupsieve==2.3.2.post1\n",
      "stable-baselines3==1.5.0\n",
      "stack-data==0.2.0\n",
      "tensorboard==2.9.0\n",
      "tensorboard-data-server==0.6.1\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "tensorflow==2.9.1\n",
      "tensorflow-estimator==2.9.0\n",
      "tensorflow-io-gcs-filesystem==0.26.0\n",
      "tensorflow-probability==0.16.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.15.0\n",
      "tf-agents==0.12.1\n",
      "tinycss2==1.1.1\n",
      "torch==1.11.0\n",
      "tornado==6.1\n",
      "traitlets==5.2.1.post0\n",
      "typing_extensions==4.2.0\n",
      "urllib3==1.26.9\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "Werkzeug==2.1.2\n",
      "widgetsnbextension==3.6.0\n",
      "wrapt==1.14.1\n",
      "zipp==3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cbd2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e63725e0-13c7-4266-9d7c-b184eab1cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3231e3b0-3283-4b14-85df-981f20c31b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0eac29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "MODELS_DIR = os.path.join(DATA_DIR, 'models')\n",
    "for dir in [DATA_DIR, MODELS_DIR]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c1960",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "513b2ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\trigu\\venv\\lib\\site-packages (22.1.2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d326422-7b1b-4b9e-8721-84e5ba266d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = \"my_secret_place/my_model\"\n",
    "PATH_TO_CFG = os.path.join(MODELS_DIR,  'pipeline.config')\n",
    "PATH_TO_CKPT = os.path.join(MODELS_DIR,  'checkpoint/')\n",
    "PATH_TO_LABELS = \"my_secret_place/my_model/label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "401d433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df220b01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m configs \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_util\u001b[49m\u001b[38;5;241m.\u001b[39mget_configs_from_pipeline_file(PATH_TO_CFG)\n\u001b[0;32m      2\u001b[0m model_config \u001b[38;5;241m=\u001b[39m configs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m detection_model \u001b[38;5;241m=\u001b[39m model_builder\u001b[38;5;241m.\u001b[39mbuild(model_config\u001b[38;5;241m=\u001b[39mmodel_config, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config_util' is not defined"
     ]
    }
   ],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392eb0f4-3293-42cd-844f-8bd937fd0b96",
   "metadata": {},
   "source": [
    "tf.train.Checkpoint - Manages saving/restoring trackable values to disk.\n",
    "TensorFlow objects may contain trackable state, such as tf.Variables, tf.keras.optimizers.Optimizer implementations, tf.data.Dataset iterators, tf.keras.Layer implementations, or tf.keras.Model implementations. These are called trackable objects.\n",
    "A Checkpoint object can be constructed to save either a single or group of trackable objects to a checkpoint file. It maintains a save_counter for numbering checkpoints.\n",
    "Checkpoint.save() and Checkpoint.restore() write and read object-based checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e19c263-7ce9-4ac8-97c4-b471dc24969f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detection_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Restore checkpoint\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv2\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(model\u001b[38;5;241m=\u001b[39m\u001b[43mdetection_model\u001b[49m)\n\u001b[0;32m      3\u001b[0m ckpt\u001b[38;5;241m.\u001b[39mrestore(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_TO_CKPT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mckpt-0\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mexpect_partial()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detection_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87edf24e-ac49-43d1-809f-0fdf81dff679",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1cd7fe1-8a74-4d85-94b8-10b5ec8e7aa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_map_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m category_index \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_map_util\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_category_index_from_labelmap(PATH_TO_LABELS,\n\u001b[0;32m      2\u001b[0m                                                                     use_display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_map_util' is not defined"
     ]
    }
   ],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2c865-e912-4c18-ad7f-f540e8f8d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_path = \"/home/jovyan/Toys/MyBarbie.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f25b6f0-ce56-4219-93ef-f93665776c0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)  # for webcam (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e972aeb-ac9a-45bf-933f-bc2c4b14772e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Read frame from camera\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     ret, image_np \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Expand dimensions since the model expects images to have shape: [1, None, None, 3]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     image_np_expanded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image_np, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret, image_np = cap.read()\n",
    "\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    \n",
    "    #################################################\n",
    "    tf.config.run_functions_eagerly(True)     #Enables / disables eager execution of tf.functions.\n",
    "  #################################################    \n",
    "    \n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "    \n",
    "    ##################################################\n",
    "    tf.config.run_functions_eagerly(False)\n",
    "    ########################################\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'][0].numpy(),\n",
    "          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "          detections['detection_scores'][0].numpy(),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "    print(detections)\n",
    "    \n",
    "\n",
    "    #Display output\n",
    "   \n",
    "    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "       break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Freenove_4WD_Smart_Car_Kit_for_Raspberry_Pi)",
   "language": "python",
   "name": "pycharm-f4e3ec95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
